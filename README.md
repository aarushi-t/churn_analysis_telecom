This is a churn analysis project used to analyze the churn rate of a telecom company. The project includes data cleaning, feature engineering, and  prediction for the churned customers
### Project Overview
In the highly competitive telecommunications industry, customer retention has become one of
the most crucial factors for sustaining business growth and profitability. One of the primary
challenges faced by telecom companies is customer churn, the phenomenon where customers
discontinue their subscription to services. High churn rates can lead to significant revenue loss
and disrupt long-term business strategies.
The methodology involves applying various machine learning algorithms, such as Decision
Trees, Random Forests, and KNN, to build an accurate prediction model. These models are
trained using historical customer data and evaluated based on metrics like accuracy,
precision, and recall to ensure reliability and effectiveness in real-world applications.

### Project Structure
The project is structured into the following sections:
1. Data Cleaning and Preprocessing
2. Feature Engineering
3. Model Selection and Training
4. Model Evaluation and Hyperparameter Tuning
5. Prediction and Deployment
### Project Requirements
The project requires the following libraries and tools:
* Python 3.8 or higher
* Pandas for data manipulation and analysis
* NumPy for numerical computations
* Scikit-learn for machine learning algorithms
* Matplotlib and Seaborn for data visualization
### Project Timeline
The project timeline is estimated to be 4 weeks, with the following milestones:
Week 1: Data Cleaning and Preprocessing
Week 2: Feature Engineering and Model Selection
Week 3: Model Training and Evaluation
Week 4: Prediction and Deployment
### Project Deliverables
The project deliverables include:
* A clean and preprocessed dataset
* A feature engineering report
* A model evaluation report
* A prediction model with high accuracy and reliability
### Project Risks
The project risks include:
* Data quality issues
* Model overfitting
* Model underfitting
### Projectt Steps
1. Data Cleaning and Preprocessing
* Import necessary libraries
* Load the dataset
* Handle missing values
* Remove duplicates
* Convert data types
2. Feature Engineering
* Select relevant features
* Apply feature scaling
* Apply feature encoding
3. Model Selection and Training
* Import necessary libraries
* Split the dataset into training and testing sets
* Train a model using the training set
* Evaluate the model using the testing set
4. Model Evaluation and Hyperparameter Tuning
* Import necessary libraries
* Evaluate the model using metrics such as accuracy, precision, and recall
* Perform hyperparameter tuning using techniques such as grid search and random search
5. Prediction and Deployment
### Project Working Steps 
1. install the requirement.txt file for the libraries
2. on the terminal write - streamlit run main.py
3. the streamlit app will be opened in the browser
4. the browser will display the app with the input field and the button

### Project output
change the file path for the excel sheets from services\get_data.py to the path of the excel sheets in your local machine
the output will be displayed in the browser as a streamlit app with the input field and the button
